{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ae2afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import make_scorer\n",
    "from lightgbm import LGBMRegressor\n",
    "import optuna\n",
    "from sklearn.base import clone\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import learning_curve, KFold  #\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from xgboost import XGBRegressor\n",
    "# Import required libraries\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "sys.path.append(os.path.join(os.path.dirname(os.getcwd()), '..'))\n",
    "from src.data.data_loader import load_raw_data\n",
    "from src.features.feature_engineering import FeatureEngineering, FlagClusteringTransformer,PreprocessingFeaturesTransformer, PreprocessingFeatures\n",
    "from category_encoders import TargetEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "030683d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-12 13:31:36,975 - src.data.data_loader - INFO - Successfully loaded 48665 rows from ../../data/raw/raw_data.csv\n"
     ]
    }
   ],
   "source": [
    "raw_data = load_raw_data('../../data/raw/raw_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4182a520",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_to_drop = [\n",
    "    \"cd_type_individual\",\n",
    "    \"cd_advertise\",\n",
    "    \"cd_client\",\n",
    "    \"flg_rain_sensor\",\n",
    "    \"flg_diesel\",\n",
    "    \"flg_eletrico\",\n",
    "    \"flg_benzina\",\n",
    "    \"flg_pcd\",\n",
    "    \"flg_trade_in\",\n",
    "    \"flg_armored\",\n",
    "    \"flg_factory_warranty\",\n",
    "    \"flg_all_dealership_schedule_vehicle\",\n",
    "    \"flg_all_dealership_services\",\n",
    "    \"flg_single_owner\",\n",
    "    \"priority\",\n",
    "    \"cd_model_vehicle\",\n",
    "    \"cd_version_vehicle\",\n",
    "    \"flg_lincese\",\n",
    "    \"flg_tax_paid\",\n",
    "    \"n_doors\",\n",
    "    \"flg_alloy_wheels\",\n",
    "    \"flg_gas_natural\",\n",
    "]\n",
    "\n",
    "pipeline_pre = Pipeline(\n",
    "    [\n",
    "        (\n",
    "            \"preprocessing\",\n",
    "            PreprocessingFeaturesTransformer(\n",
    "                location_col=\"city_state\",\n",
    "                fuel_type_column=\"fuel_type\",\n",
    "                cols_to_drop=feat_to_drop,\n",
    "                outlier_columns=[\"vl_advertise\", \"km_vehicle\"],\n",
    "            ),\n",
    "        ),\n",
    "        (\n",
    "            \"feat_engineering\",\n",
    "            FlagClusteringTransformer(\n",
    "                feature_flag_cols=[\n",
    "                    \"flg_gasolina\",\n",
    "                    \"flg_electric_locks\",\n",
    "                    \"flg_air_conditioning\",\n",
    "                    \"flg_electric_windows\",\n",
    "                    \"flg_rear_defogger\",\n",
    "                    \"flg_heater\",\n",
    "                    \"flg_alarm\",\n",
    "                    \"flg_airbag\",\n",
    "                    \"flg_abs\",\n",
    "                ]\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5c3a43c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-12 13:31:36,994 - src.features.feature_engineering - INFO - üìà Numerical features: 5\n",
      "2025-08-12 13:31:36,995 - src.features.feature_engineering - INFO - üè∑Ô∏è Categorical features: 35\n",
      "2025-08-12 13:31:36,995 - src.features.feature_engineering - INFO - üéØ Target variable: ['flg_leads', 'leads']\n",
      "2025-08-12 13:31:36,996 - src.features.feature_engineering - INFO - Runnig location split...\n",
      "2025-08-12 13:31:38,585 - src.features.feature_engineering - INFO - Converting flag columns to integer type...\n",
      "2025-08-12 13:31:38,774 - src.features.feature_engineering - INFO - Flag columns converted to integer type successfully\n",
      "2025-08-12 13:31:38,775 - src.features.feature_engineering - INFO - Converting fuel type to flag columns...\n",
      "2025-08-12 13:31:38,777 - src.features.feature_engineering - INFO - Found 7 unique fuel types: ['alcool', 'gasolina', 'gas', 'natural', 'diesel', 'eletrico', 'benzina']\n",
      "2025-08-12 13:31:38,892 - src.features.feature_engineering - INFO - Removing duplicate columns...\n",
      "2025-08-12 13:31:38,893 - src.features.feature_engineering - INFO - No duplicate columns found\n",
      "2025-08-12 13:31:38,972 - src.features.feature_engineering - INFO - Cleaning spurious values...\n",
      "2025-08-12 13:31:38,981 - src.features.feature_engineering - WARNING - Found 2 rows with -1 values, removing them\n",
      "2025-08-12 13:31:39,014 - src.features.feature_engineering - INFO - vl_advertise:\n",
      "2025-08-12 13:31:39,015 - src.features.feature_engineering - INFO -   - Lower bound (1.0%): -816139.08 (0 outliers)\n",
      "2025-08-12 13:31:39,015 - src.features.feature_engineering - INFO -   - Upper bound (99.0%): 1115918.46 (49 outliers)\n",
      "2025-08-12 13:31:39,016 - src.features.feature_engineering - INFO -   - Total outliers: 49 (0.10%)\n",
      "2025-08-12 13:31:39,022 - src.features.feature_engineering - INFO -   - Rows removed: 0n\n",
      "2025-08-12 13:31:39,025 - src.features.feature_engineering - INFO - km_vehicle:\n",
      "2025-08-12 13:31:39,025 - src.features.feature_engineering - INFO -   - Lower bound (1.0%): -809841.66 (0 outliers)\n",
      "2025-08-12 13:31:39,025 - src.features.feature_engineering - INFO -   - Upper bound (99.0%): 1079788.88 (67 outliers)\n",
      "2025-08-12 13:31:39,026 - src.features.feature_engineering - INFO -   - Total outliers: 67 (0.14%)\n",
      "2025-08-12 13:31:39,036 - src.features.feature_engineering - INFO -   - Rows removed: 0n\n",
      "2025-08-12 13:31:39,037 - src.features.feature_engineering - INFO - Setting up features...\n",
      "2025-08-12 13:31:39,050 - src.features.feature_engineering - INFO - Feature setup completed successfully\n",
      "2025-08-12 13:31:39,054 - src.features.feature_engineering - INFO - Fitting FlagClusteringTransformer...\n",
      "2025-08-12 13:31:39,055 - src.features.feature_engineering - INFO - Using flag columns: ['flg_gasolina', 'flg_electric_locks', 'flg_air_conditioning', 'flg_electric_windows', 'flg_rear_defogger', 'flg_heater', 'flg_alarm', 'flg_airbag', 'flg_abs']\n",
      "2025-08-12 13:31:39,060 - src.features.feature_engineering - INFO - Processing 9 flag columns: ['flg_gasolina', 'flg_electric_locks', 'flg_air_conditioning', 'flg_electric_windows', 'flg_rear_defogger', 'flg_heater', 'flg_alarm', 'flg_airbag', 'flg_abs']\n",
      "2025-08-12 13:31:39,089 - src.features.feature_engineering - INFO - Grouped data by flag combinations, resulting in 10 unique sum_flags\n",
      "2025-08-12 13:31:39,089 - src.features.feature_engineering - INFO - Flag clustering features created successfully\n",
      "2025-08-12 13:31:39,091 - src.features.feature_engineering - INFO - Fitted Jenks model with 5 clusters\n",
      "2025-08-12 13:31:39,091 - src.features.feature_engineering - INFO - Cluster breaks: [3.2922202603188966, 3.458400781214529, 4.083840620938378, 4.651612903225806, 5.592657725433033, 6.064817476286289]\n",
      "2025-08-12 13:31:39,092 - src.features.feature_engineering - INFO - FlagClusteringTransformer fitted successfully\n",
      "2025-08-12 13:31:39,094 - src.features.feature_engineering - INFO - Using 9 available flag columns: ['flg_gasolina', 'flg_electric_locks', 'flg_air_conditioning', 'flg_electric_windows', 'flg_rear_defogger', 'flg_heater', 'flg_alarm', 'flg_airbag', 'flg_abs']\n",
      "2025-08-12 13:31:39,101 - src.features.feature_engineering - INFO - Dropping columns: ['flg_gasolina', 'flg_electric_locks', 'flg_air_conditioning', 'flg_electric_windows', 'flg_rear_defogger', 'flg_heater', 'flg_alarm', 'flg_airbag', 'flg_abs', 'sum_flags']\n",
      "2025-08-12 13:31:39,105 - src.features.feature_engineering - INFO - Dropped original flag columns and sum_flags\n",
      "2025-08-12 13:31:39,105 - src.features.feature_engineering - INFO - Transformed data with 10 flag columns\n"
     ]
    }
   ],
   "source": [
    "df_processed = pipeline_pre.fit_transform(\n",
    "            raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0accd15f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['leads', 'views', 'phone_clicks', 'cd_vehicle_brand', 'year_model',\n",
       "       'zip_2dig', 'vl_advertise', 'n_photos', 'km_vehicle', 'vl_market',\n",
       "       'transmission_type', 'flg_leather_seats', 'flg_parking_sensor', 'city',\n",
       "       'state', 'flg_alcool', 'flag_cluster'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_processed.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "eacbdf6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in X_train: Index(['views', 'phone_clicks', 'cd_vehicle_brand', 'year_model', 'zip_2dig',\n",
      "       'vl_advertise', 'n_photos', 'km_vehicle', 'vl_market',\n",
      "       'transmission_type', 'flg_leather_seats', 'flg_parking_sensor', 'city',\n",
      "       'state', 'flg_alcool', 'flag_cluster'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Fit the pipeline\n",
    "X = df_processed.drop('leads', axis=1)  # Features\n",
    "y = df_processed['leads']  # Target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Check the column names to ensure all required columns exist\n",
    "print(\"Columns in X_train:\", X_train.columns)\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('encoding', ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('city', TargetEncoder(cols=['city'], smoothing=0.5, min_samples_leaf=1000), ['city']),\n",
    "            ('state', TargetEncoder(cols=['state'], smoothing=5, min_samples_leaf=500), ['state']),\n",
    "            ('scaler', StandardScaler(), ['views', 'phone_clicks', 'vl_advertise', 'km_vehicle', 'vl_market']),\n",
    "            ('transmission', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1), ['transmission_type'])\n",
    "        ],\n",
    "        remainder='passthrough'  # Keep the other columns unchanged\n",
    "    )),\n",
    "    ('model', LGBMRegressor(learning_rate=0.01, reg_alpha=1, num_leaves=20, max_depth=10, n_estimators=300,))  # LightGBM Regressor\n",
    "])\n",
    "\n",
    "# Set up K-fold cross-validation with stratification on the training data\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a64f276c",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # param = {\n",
    "    #     \"objective\": \"regression\",\n",
    "    #     \"metric\": \"rmse\",\n",
    "    #     \"n_estimators\": 1000,\n",
    "    #     \"verbosity\": -1,\n",
    "    #     \"bagging_freq\": 1,\n",
    "    #     \"early_stopping_rounds\":150, \n",
    "    #     \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.1, log=True),\n",
    "    #     \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 50),\n",
    "    #     \"subsample\": trial.suggest_float(\"subsample\", 0.05, 1.0),\n",
    "    #     \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.05, 1.0),\n",
    "    #     \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 1, 100),\n",
    "    #     'feature_fraction': trial.suggest_uniform('feature_fraction', 0.1, 1.0),\n",
    "    # }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "98ada820",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 16:47:21,995] A new study created in memory with name: no-name-d418567a-2bf1-407a-9020-b8080603372e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 150 rounds\n",
      "Early stopping, best iteration is:\n",
      "[331]\tvalid_0's l2: 46.0052\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "Early stopping, best iteration is:\n",
      "[188]\tvalid_0's l2: 47.9835\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[309]\tvalid_0's l2: 52.246\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[728]\tvalid_0's l2: 90.1026\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "Early stopping, best iteration is:\n",
      "[347]\tvalid_0's l2: 49.8943\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[833]\tvalid_0's l2: 52.8825\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "Early stopping, best iteration is:\n",
      "[205]\tvalid_0's l2: 50.9273\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[621]\tvalid_0's l2: 103.359\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[640]\tvalid_0's l2: 107.302\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "Early stopping, best iteration is:\n",
      "[105]\tvalid_0's l2: 52.5768\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[456]\tvalid_0's l2: 47.723\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[419]\tvalid_0's l2: 47.9716\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[470]\tvalid_0's l2: 49.5761\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "Early stopping, best iteration is:\n",
      "[633]\tvalid_0's l2: 48.5137\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[482]\tvalid_0's l2: 53.2988\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[996]\tvalid_0's l2: 53.5047\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[298]\tvalid_0's l2: 45.7001\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[280]\tvalid_0's l2: 47.6222\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[479]\tvalid_0's l2: 48.0003\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "Early stopping, best iteration is:\n",
      "[379]\tvalid_0's l2: 51.567\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[772]\tvalid_0's l2: 46.3986\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[758]\tvalid_0's l2: 46.8022\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "Early stopping, best iteration is:\n",
      "[181]\tvalid_0's l2: 47.4063\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "Early stopping, best iteration is:\n",
      "[578]\tvalid_0's l2: 49.3337\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[758]\tvalid_0's l2: 53.0185\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[304]\tvalid_0's l2: 47.8144\n",
      "Training until validation scores don't improve for 150 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 26 failed with parameters: {'n_estimators': 538, 'learning_rate': 0.010450479446745447, 'num_leaves': 43, 'max_depth': 6, 'min_data_in_leaf': 24, 'feature_fraction': 0.8491732747680776, 'early_stopping_rounds': 150} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/algelopelisson/Documents/DataScience/projetos/leads-analysis-prediction/venv/lib/python3.13/site-packages/optuna/study/_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/p8/n44gv6mn7z193xr0hyjsfwgh0000gp/T/ipykernel_23863/463207720.py\", line 20, in objective\n",
      "    model.fit(X_tr, y_train, eval_set=[(X_te, y_test)])\n",
      "    ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/algelopelisson/Documents/DataScience/projetos/leads-analysis-prediction/venv/lib/python3.13/site-packages/lightgbm/sklearn.py\", line 1398, in fit\n",
      "    super().fit(\n",
      "    ~~~~~~~~~~~^\n",
      "        X,\n",
      "        ^^\n",
      "    ...<11 lines>...\n",
      "        init_model=init_model,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/algelopelisson/Documents/DataScience/projetos/leads-analysis-prediction/venv/lib/python3.13/site-packages/lightgbm/sklearn.py\", line 1049, in fit\n",
      "    self._Booster = train(\n",
      "                    ~~~~~^\n",
      "        params=params,\n",
      "        ^^^^^^^^^^^^^^\n",
      "    ...<6 lines>...\n",
      "        callbacks=callbacks,\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/algelopelisson/Documents/DataScience/projetos/leads-analysis-prediction/venv/lib/python3.13/site-packages/lightgbm/engine.py\", line 322, in train\n",
      "    booster.update(fobj=fobj)\n",
      "    ~~~~~~~~~~~~~~^^^^^^^^^^^\n",
      "  File \"/Users/algelopelisson/Documents/DataScience/projetos/leads-analysis-prediction/venv/lib/python3.13/site-packages/lightgbm/basic.py\", line 4155, in update\n",
      "    _LIB.LGBM_BoosterUpdateOneIter(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._handle,\n",
      "        ^^^^^^^^^^^^^\n",
      "        ctypes.byref(is_finished),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "KeyboardInterrupt\n",
      "Trial 26 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[60]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     25\u001b[39m study = optuna.create_study(direction=\u001b[33m'\u001b[39m\u001b[33mminimize\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     26\u001b[39m optuna.logging.disable_default_handler()\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m150\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DataScience/projetos/leads-analysis-prediction/venv/lib/python3.13/site-packages/optuna/study/study.py:489\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    387\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    388\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    389\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    396\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    397\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    398\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    399\u001b[39m \n\u001b[32m    400\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    487\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    488\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m489\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DataScience/projetos/leads-analysis-prediction/venv/lib/python3.13/site-packages/optuna/study/_optimize.py:64\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     77\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DataScience/projetos/leads-analysis-prediction/venv/lib/python3.13/site-packages/optuna/study/_optimize.py:161\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    158\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m     frozen_trial = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    167\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DataScience/projetos/leads-analysis-prediction/venv/lib/python3.13/site-packages/optuna/study/_optimize.py:253\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    246\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    249\u001b[39m     frozen_trial.state == TrialState.FAIL\n\u001b[32m    250\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    251\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    252\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DataScience/projetos/leads-analysis-prediction/venv/lib/python3.13/site-packages/optuna/study/_optimize.py:201\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    200\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    202\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    203\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    204\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[60]\u001b[39m\u001b[32m, line 20\u001b[39m, in \u001b[36mobjective\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m      9\u001b[39m param = {\n\u001b[32m     10\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mreg_alpha\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m1\u001b[39m,\n\u001b[32m     11\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mn_estimators\u001b[39m\u001b[33m'\u001b[39m: trial.suggest_int(\u001b[33m'\u001b[39m\u001b[33mn_estimators\u001b[39m\u001b[33m'\u001b[39m, \u001b[32m300\u001b[39m, \u001b[32m1000\u001b[39m),\n\u001b[32m   (...)\u001b[39m\u001b[32m     17\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mearly_stopping_rounds\u001b[39m\u001b[33m'\u001b[39m: trial.suggest_int(\u001b[33m'\u001b[39m\u001b[33mearly_stopping_rounds\u001b[39m\u001b[33m'\u001b[39m, \u001b[32m150\u001b[39m,\u001b[32m150\u001b[39m)\n\u001b[32m     18\u001b[39m }\n\u001b[32m     19\u001b[39m model = LGBMRegressor(**param)\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_te\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m preds = model.predict(X_te)\n\u001b[32m     22\u001b[39m mse = mean_squared_error(y_test, preds)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DataScience/projetos/leads-analysis-prediction/venv/lib/python3.13/site-packages/lightgbm/sklearn.py:1398\u001b[39m, in \u001b[36mLGBMRegressor.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[39m\n\u001b[32m   1381\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit\u001b[39m(  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[32m   1382\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1383\u001b[39m     X: _LGBM_ScikitMatrixLike,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1395\u001b[39m     init_model: Optional[Union[\u001b[38;5;28mstr\u001b[39m, Path, Booster, LGBMModel]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1396\u001b[39m ) -> \u001b[33m\"\u001b[39m\u001b[33mLGBMRegressor\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1397\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Docstring is inherited from the LGBMModel.\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1398\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1399\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1400\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1401\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1402\u001b[39m \u001b[43m        \u001b[49m\u001b[43minit_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43minit_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1403\u001b[39m \u001b[43m        \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1404\u001b[39m \u001b[43m        \u001b[49m\u001b[43meval_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1405\u001b[39m \u001b[43m        \u001b[49m\u001b[43meval_sample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1406\u001b[39m \u001b[43m        \u001b[49m\u001b[43meval_init_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_init_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1407\u001b[39m \u001b[43m        \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1408\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1409\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1410\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1411\u001b[39m \u001b[43m        \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1412\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1413\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DataScience/projetos/leads-analysis-prediction/venv/lib/python3.13/site-packages/lightgbm/sklearn.py:1049\u001b[39m, in \u001b[36mLGBMModel.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[39m\n\u001b[32m   1046\u001b[39m evals_result: _EvalResultDict = {}\n\u001b[32m   1047\u001b[39m callbacks.append(record_evaluation(evals_result))\n\u001b[32m-> \u001b[39m\u001b[32m1049\u001b[39m \u001b[38;5;28mself\u001b[39m._Booster = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1050\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1051\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1052\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_estimators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1053\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1054\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalid_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1055\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeval\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_metrics_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   1056\u001b[39m \u001b[43m    \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1057\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1058\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1060\u001b[39m \u001b[38;5;66;03m# This populates the property self.n_features_, the number of features in the fitted model,\u001b[39;00m\n\u001b[32m   1061\u001b[39m \u001b[38;5;66;03m# and so should only be set after fitting.\u001b[39;00m\n\u001b[32m   1062\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m   1063\u001b[39m \u001b[38;5;66;03m# The related property self._n_features_in, which populates self.n_features_in_,\u001b[39;00m\n\u001b[32m   1064\u001b[39m \u001b[38;5;66;03m# is set BEFORE fitting.\u001b[39;00m\n\u001b[32m   1065\u001b[39m \u001b[38;5;28mself\u001b[39m._n_features = \u001b[38;5;28mself\u001b[39m._Booster.num_feature()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DataScience/projetos/leads-analysis-prediction/venv/lib/python3.13/site-packages/lightgbm/engine.py:322\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, keep_training_booster, callbacks)\u001b[39m\n\u001b[32m    310\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m callbacks_before_iter:\n\u001b[32m    311\u001b[39m     cb(\n\u001b[32m    312\u001b[39m         callback.CallbackEnv(\n\u001b[32m    313\u001b[39m             model=booster,\n\u001b[32m   (...)\u001b[39m\u001b[32m    319\u001b[39m         )\n\u001b[32m    320\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m322\u001b[39m \u001b[43mbooster\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    324\u001b[39m evaluation_result_list: List[_LGBM_BoosterEvalMethodResultType] = []\n\u001b[32m    325\u001b[39m \u001b[38;5;66;03m# check evaluation result.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DataScience/projetos/leads-analysis-prediction/venv/lib/python3.13/site-packages/lightgbm/basic.py:4155\u001b[39m, in \u001b[36mBooster.update\u001b[39m\u001b[34m(self, train_set, fobj)\u001b[39m\n\u001b[32m   4152\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__set_objective_to_none:\n\u001b[32m   4153\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(\u001b[33m\"\u001b[39m\u001b[33mCannot update due to null objective function.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   4154\u001b[39m _safe_call(\n\u001b[32m-> \u001b[39m\u001b[32m4155\u001b[39m     \u001b[43m_LIB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mLGBM_BoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4156\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4157\u001b[39m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mis_finished\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4158\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4159\u001b[39m )\n\u001b[32m   4160\u001b[39m \u001b[38;5;28mself\u001b[39m.__is_predicted_cur_iter = [\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.__num_dataset)]\n\u001b[32m   4161\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m is_finished.value == \u001b[32m1\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "prep = clone(pipeline.named_steps[\"encoding\"])\n",
    "\n",
    "prep.fit(X_train, y_train)\n",
    "X_tr = prep.transform(X_train)\n",
    "X_te = prep.transform(X_test)\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'reg_alpha': 1,\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 300, 1000),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.1),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 100),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 10, 50),\n",
    "        'feature_fraction': trial.suggest_uniform('feature_fraction', 0.3, 1.0),\n",
    "        'early_stopping_rounds': trial.suggest_int('early_stopping_rounds', 150,150)\n",
    "    }\n",
    "    model = LGBMRegressor(**param)\n",
    "    model.fit(X_tr, y_train, eval_set=[(X_te, y_test)])\n",
    "    preds = model.predict(X_te)\n",
    "    mse = mean_squared_error(y_test, preds)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse\n",
    "study = optuna.create_study(direction='minimize')\n",
    "optuna.logging.disable_default_handler()\n",
    "study.optimize(objective, n_trials=150)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cfa799d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 326, 'learning_rate': 0.019077681491088343, 'num_leaves': 26, 'max_depth': 5, 'min_data_in_leaf': 15, 'feature_fraction': 0.7656754625414294, 'verbosity': -1}\n"
     ]
    }
   ],
   "source": [
    "best_params = study.best_params\n",
    "best_params[\"verbosity\"] = -1\n",
    "best_params.pop('early_stopping_rounds', None) \n",
    "print(best_params) # Remove early_stopping_rounds if it exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "103c4fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE baseline: 135.5174330920903\n"
     ]
    }
   ],
   "source": [
    "baseline_pred = np.full_like(y_train, y_train.mean(), dtype=float)\n",
    "baseline_mse = np.mean((y_train - baseline_pred) ** 2)\n",
    "\n",
    "print(\"MSE baseline:\", baseline_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05de6f0f",
   "metadata": {},
   "source": [
    "## Avalia√ß√£o de Curva de Aprendizado e Overfitting\n",
    "\n",
    "Vamos plotar a curva de aprendizado (learning curve) para avaliar se h√° overfitting/underfitting e tamb√©m refor√ßar a an√°lise com o scatter plot de valores reais vs preditos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5527b801",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# ===== 1) Curva de aprendizado (RMSE) =====\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "pipeline.named_steps['model'].set_params(**best_params)\n",
    "\n",
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "    estimator=pipeline,\n",
    "    X=X_train, y=y_train,\n",
    "    cv=cv,\n",
    "    scoring='neg_root_mean_squared_error',  # j√° √© RMSE com sinal negativo\n",
    "    train_sizes=np.linspace(0.1, 1.0, 8),\n",
    "    n_jobs=-1,\n",
    "    shuffle=True,\n",
    "    random_state=42,\n",
    "    return_times=False\n",
    ")\n",
    "\n",
    "# Como a m√©trica √© \"neg_root_mean_squared_error\", basta inverter o sinal:\n",
    "train_rmse = -train_scores\n",
    "test_rmse  = -test_scores\n",
    "\n",
    "train_mean = train_rmse.mean(axis=1)\n",
    "train_std  = train_rmse.std(axis=1)\n",
    "test_mean  = test_rmse.mean(axis=1)\n",
    "test_std   = test_rmse.std(axis=1)\n",
    "\n",
    "gap = test_mean - train_mean\n",
    "gap_ratio = gap / np.maximum(train_mean, 1e-9)  # prote√ß√£o contra div/0\n",
    "\n",
    "# Heur√≠stica p/ detectar in√≠cio de overfitting:\n",
    "# - limiar relativo (ex.: 10%)\n",
    "# - precisa manter por algumas fra√ß√µes consecutivas (estabilidade)\n",
    "threshold = 0.10\n",
    "min_consecutive = 2\n",
    "start_idx = None\n",
    "streak = 0\n",
    "for i in range(len(train_sizes)):\n",
    "    if gap_ratio[i] > threshold:\n",
    "        streak += 1\n",
    "        if streak >= min_consecutive:\n",
    "            start_idx = i - min_consecutive + 1\n",
    "            break\n",
    "    else:\n",
    "        streak = 0\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_sizes, train_mean, 'o-', label='Train RMSE')\n",
    "plt.plot(train_sizes, test_mean, 'o-', label='Validation RMSE')\n",
    "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.15)\n",
    "plt.fill_between(train_sizes, test_mean - test_std,   test_mean + test_std,   alpha=0.15)\n",
    "plt.xlabel('Training Set Size')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('Learning Curve (RMSE)')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "if start_idx is not None:\n",
    "    x0 = train_sizes[start_idx]\n",
    "    y0 = test_mean[start_idx]\n",
    "    plt.axvline(x0, linestyle='--', alpha=0.6)\n",
    "    plt.annotate(\n",
    "        f'In√≠cio prov√°vel do overfitting\\n(gap > {int(threshold*100)}%)',\n",
    "        xy=(x0, y0),\n",
    "        xytext=(x0, y0 + (test_mean.max()-test_mean.min())*0.15),\n",
    "        arrowprops=dict(arrowstyle='->', lw=1),\n",
    "        ha='center'\n",
    "    )\n",
    "plt.show()\n",
    "\n",
    "# Diagn√≥stico textual (√∫ltimo ponto)\n",
    "last_gap = gap[-1]\n",
    "last_ratio = gap_ratio[-1]\n",
    "if last_ratio > threshold:\n",
    "    print(f\"‚ö†Ô∏è Poss√≠vel overfitting (√∫ltimo ponto): gap={last_gap:.3f}, gap/train={last_ratio:.1%} (> {threshold:.0%})\")\n",
    "else:\n",
    "    print(f\"‚úÖ Sem sinais claros no √∫ltimo ponto: gap={last_gap:.3f}, gap/train={last_ratio:.1%} (‚â§ {threshold:.0%})\")\n",
    "\n",
    "# ===== 2) Fit final no treino e avalia√ß√£o no teste =====\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "mse  = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2   = r2_score(y_test, y_pred)\n",
    "print(f\"Teste: RMSE={rmse:.3f} | MSE={mse:.3f} | R¬≤={r2:.3f}\")\n",
    "\n",
    "# ===== 3) Scatter Real vs Predito + linha ideal =====\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x=y_test, y=y_pred, alpha=0.5, s=20, edgecolor=None)\n",
    "lims = [min(y_test.min(), y_pred.min()), max(y_test.max(), y_pred.max())]\n",
    "plt.plot(lims, lims, 'r--', label='Ideal')\n",
    "plt.xlabel('Valores Reais')\n",
    "plt.ylabel('Valores Preditos')\n",
    "plt.title('Valores Reais vs. Preditos')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# (Opcional) Res√≠duos\n",
    "res = y_test - y_pred\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.histplot(res, bins=40, kde=True)\n",
    "plt.title('Distribui√ß√£o dos Res√≠duos (y_true - y_pred)')\n",
    "plt.xlabel('Res√≠duo')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05702f1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
